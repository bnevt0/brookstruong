---
title: "AT2 Modelling by AB"
author: "Alex Brooks"
date: "29 September 2018"
output: html_document
---

```{r setup, include=FALSE, error=FALSE, message=FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse, quietly = T)
library(ggplot2, quietly = T)
library(caret, quietly = T)
library(dplyr, quietly = T)
library(ROCR, quietly = T)
library(glmnet, quietly = T)
library(xgboost, quietly = T)
```

# Start modelling

EVALUATE THE MODEL: using AUC (area under the ROC curve) for binary classification models on the validation data.

```{r}
#Import the data
training.raw <- read.csv('AT2_credit_train_STUDENT.csv', header = TRUE)
predict.raw <- read.csv('AT2_credit_test_STUDENT.csv', header = TRUE)
```
##Clean the data based on observations

```{r}
#need to change ID to be "character", so the IDs are not counted as numbers

clean_data <- function(dataSet) {
  
  #clean up sex, call it new_sex and change the animal classifications to 0
  output <- dataSet
  
  output$ID <- as.character(output$ID)
  
  output$SEX <- as.integer(output$SEX)
  
  output$SEX[output$SEX > 2] <- 0
  
  output$EDUCATION[output$EDUCATION > 4] <- 4
  output$EDUCATION[output$EDUCATION == 0] <- 4
  
  #clean age to remove aged over 100 entries will become NA
  output$AGE <- ifelse(output$AGE >=100, NA, output$AGE)
  
  output$AGE[is.na(output$AGE)] <- round(mean(output$AGE[!is.na(output$AGE)]))
  
  output$MARRIAGE[output$MARRIAGE == 0] <- 3
  
  #removed these factors from modelling to make them integers
  output$SEX <- as.factor(output$SEX)
  output$EDUCATION <- as.factor(output$EDUCATION)
  output$MARRIAGE <- as.factor(output$MARRIAGE)
  
  #output$AGE_BRACKET <- NA
  
  #output$AGE_BRACKET[output$AGE < 32] <- 1
  #output$AGE_BRACKET[output$AGE >= 32 & output$AGE < 43 ] <- 2
  #output$AGE_BRACKET[output$AGE >= 43 & output$AGE < 54 ] <- 3
  #output$AGE_BRACKET[output$AGE >= 54 & output$AGE < 65 ] <- 4
  #output$AGE_BRACKET[output$AGE >= 65] <- 5
  #output$AGE_BRACKET <- as.factor(output$AGE_BRACKET)
  #output$AGE <- NULL
  
  return(output)
}
```

Create some standard functions for measuring evaulation criteria

```{r}
# We'll want to look at evaluation measures regularly, so create a function to calculate and return them
get_evaluation_measures <- function(name = NA, tn, fp, fn, tp) {
  
  accuracy = (tp+tn)/(tp+tn+fp+fn)
  
  precision = tp/(tp+fp)
  
  recall = tp/(tp+fn)
  
  F1 = 2 * ((precision * recall)/(precision + recall))
  
  output = data.frame(name, accuracy, precision, recall, F1)
  
  return(output)
  
}
```

```{r}
#Now to get AUC. We'll do it again further on in our analysis, so write a function
get_auc <- function(probabilities, targets) {
  
  probs = as.vector(probabilities)
  
  pred = prediction(probs,targets)
  
  perf_AUC = performance(pred, "auc")
  
  AUC = perf_AUC@y.values[[1]]
  
  return(AUC)
  
}
```

Clean our training data
```{r}
training.clean <- clean_data(training.raw)
```

Now to try XG boost

```{r}
# fit model

boost.training.clean = training.clean[complete.cases(training.clean), ]

boost.training.clean$default <- as.character(boost.training.clean$default)

boost.training.clean$default[boost.training.clean$default == "N"] = 0
boost.training.clean$default[boost.training.clean$default == "Y"] = 1

boost.training.clean$default <- as.numeric(as.factor(boost.training.clean$default))-1

#create test and train set dataframes
set.seed(42)

boost.training.rows <- createDataPartition(y = boost.training.clean$default, p=0.8, list=F)

boost.test.set <- boost.training.clean %>% filter(!(rownames(.) %in% boost.training.rows))
boost.train.set <- boost.training.clean %>% filter(rownames(.) %in% boost.training.rows)

boost.full.matrix <-sparse.model.matrix(default ~., boost.training.clean[,-1])
boost.train.matrix <-sparse.model.matrix(default ~., boost.train.set[,-1])
boost.test.matrix <-sparse.model.matrix(default ~., boost.test.set[,-1])

boost.model <- xgboost(data = boost.train.matrix, label = boost.train.set$default, max.depth = 5, eta = 1, nrounds = 100, nthread = 1, objective = "binary:logistic", eval_metric="auc")
# predict
boost.prob <- predict(boost.model, newdata = boost.test.matrix)

# Create a vector to hold predictions,turn it from a probability to a prediction
boost.predictions <- rep(0,nrow(boost.test.set[,-1]))
boost.predictions[boost.prob >.5] <- 1

#Create a confusion matrix
boost.cm <- table(pred=boost.predictions, true=boost.test.set$default)

#converted CM to dataframe extracted the frequency values for each score
boost.df <- as.data.frame(boost.cm)

#Calculate our evaluation measures and place them in a data frame
boost.eval <- get_evaluation_measures("XGBoost",
                                         boost.df$Freq[1],
                                         boost.df$Freq[2],
                                         boost.df$Freq[3],
                                         boost.df$Freq[4])


boost.eval$AUC <- get_auc(boost.prob, boost.test.set$default)

boost.eval

```